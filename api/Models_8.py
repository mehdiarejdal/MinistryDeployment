{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path='/home/elmehdi.arejdal/lustre/data_sec-um6p-st-sccs-6sevvl76uja/IDS/Ismail_Elbouknify/Ministry/_General_approach_/1_1_college/Data_middle_2.csv'\n",
    "data=pd.read_csv(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_eleve</th>\n",
       "      <th>id_annee</th>\n",
       "      <th>cd_etab</th>\n",
       "      <th>id_classe</th>\n",
       "      <th>MoyenneGen_i1</th>\n",
       "      <th>NbrJourAbsenceAutorise_i1</th>\n",
       "      <th>NbrUniteAbsenceAutorise_i1</th>\n",
       "      <th>NbrJourAbsenceNonAutorise_i1</th>\n",
       "      <th>NbrUniteAbsenceNonAutorise_i1</th>\n",
       "      <th>MCaRtable_i1</th>\n",
       "      <th>istayssir_i1</th>\n",
       "      <th>White_year_i1</th>\n",
       "      <th>target_i1</th>\n",
       "      <th>international_i1</th>\n",
       "      <th>Level_i1</th>\n",
       "      <th>failure_i1</th>\n",
       "      <th>Classment_class_i1</th>\n",
       "      <th>Nb_class_failure_i1</th>\n",
       "      <th>Nb_class_dropout_i1</th>\n",
       "      <th>nbr_eleves_i1</th>\n",
       "      <th>nbr_filles_i1</th>\n",
       "      <th>MoyenneClasse_i1</th>\n",
       "      <th>Multiclass_i1</th>\n",
       "      <th>CD_REG_i1</th>\n",
       "      <th>cd_prov_i1</th>\n",
       "      <th>DO_ETAB_i1</th>\n",
       "      <th>Internat_i1</th>\n",
       "      <th>Exist_Internet_i1</th>\n",
       "      <th>AdresseL_i1</th>\n",
       "      <th>INDHcom_i1</th>\n",
       "      <th>INDHquart_i1</th>\n",
       "      <th>ProgrammeTissir_i1</th>\n",
       "      <th>Coefficients_CC_11_i1</th>\n",
       "      <th>Coefficients_CC_12_i1</th>\n",
       "      <th>Coefficients_CC_18_i1</th>\n",
       "      <th>Coefficients_CC_19_i1</th>\n",
       "      <th>Coefficients_CC_20_i1</th>\n",
       "      <th>Coefficients_CC_23_i1</th>\n",
       "      <th>Coefficients_CC_24_i1</th>\n",
       "      <th>Coefficients_CC_26_i1</th>\n",
       "      <th>NoteCC_11_i1</th>\n",
       "      <th>NoteCC_12_i1</th>\n",
       "      <th>NoteCC_18_i1</th>\n",
       "      <th>NoteCC_19_i1</th>\n",
       "      <th>NoteCC_20_i1</th>\n",
       "      <th>NoteCC_23_i1</th>\n",
       "      <th>NoteCC_24_i1</th>\n",
       "      <th>NoteCC_26_i1</th>\n",
       "      <th>target</th>\n",
       "      <th>id_genre</th>\n",
       "      <th>datenaiseleve</th>\n",
       "      <th>nationalite</th>\n",
       "      <th>id_handicap</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Préscolarisé</th>\n",
       "      <th>profession_mere</th>\n",
       "      <th>profession_pere</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6048644</td>\n",
       "      <td>8</td>\n",
       "      <td>26186M</td>\n",
       "      <td>000B0B06-2DE7-4962-A248-DF7EB9487CD0</td>\n",
       "      <td>17.31</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marjane 4 sidi bouzekri</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.19</td>\n",
       "      <td>12.55</td>\n",
       "      <td>17.81</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.435</td>\n",
       "      <td>18.92</td>\n",
       "      <td>14.335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>حي الانارة زنقة1 درب16 رقم 173 مكناس</td>\n",
       "      <td>1</td>\n",
       "      <td>inconnu</td>\n",
       "      <td>Général</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_eleve  id_annee cd_etab                             id_classe  \\\n",
       "0   6048644         8  26186M  000B0B06-2DE7-4962-A248-DF7EB9487CD0   \n",
       "\n",
       "   MoyenneGen_i1  NbrJourAbsenceAutorise_i1  NbrUniteAbsenceAutorise_i1  \\\n",
       "0          17.31                       40.0                         0.0   \n",
       "\n",
       "   NbrJourAbsenceNonAutorise_i1  NbrUniteAbsenceNonAutorise_i1  MCaRtable_i1  \\\n",
       "0                           0.0                            0.0             0   \n",
       "\n",
       "   istayssir_i1  White_year_i1  target_i1  international_i1  Level_i1  \\\n",
       "0             0              0          0                 0         8   \n",
       "\n",
       "   failure_i1  Classment_class_i1  Nb_class_failure_i1  Nb_class_dropout_i1  \\\n",
       "0           0                   1                   16                    4   \n",
       "\n",
       "   nbr_eleves_i1  nbr_filles_i1  MoyenneClasse_i1  Multiclass_i1  CD_REG_i1  \\\n",
       "0           45.0           26.0              9.88            1.0          3   \n",
       "\n",
       "   cd_prov_i1  DO_ETAB_i1  Internat_i1  Exist_Internet_i1  \\\n",
       "0          61        2014            0                  0   \n",
       "\n",
       "                AdresseL_i1  INDHcom_i1  INDHquart_i1  ProgrammeTissir_i1  \\\n",
       "0  marjane 4 sidi bouzekri            0             0                   1   \n",
       "\n",
       "   Coefficients_CC_11_i1  Coefficients_CC_12_i1  Coefficients_CC_18_i1  \\\n",
       "0                    5.0                    5.0                    3.0   \n",
       "\n",
       "   Coefficients_CC_19_i1  Coefficients_CC_20_i1  Coefficients_CC_23_i1  \\\n",
       "0                    5.0                    3.0                    2.0   \n",
       "\n",
       "   Coefficients_CC_24_i1  Coefficients_CC_26_i1  NoteCC_11_i1  NoteCC_12_i1  \\\n",
       "0                    2.0                    2.0         18.19         12.55   \n",
       "\n",
       "   NoteCC_18_i1  NoteCC_19_i1  NoteCC_20_i1  NoteCC_23_i1  NoteCC_24_i1  \\\n",
       "0         17.81          20.0          18.5        18.435         18.92   \n",
       "\n",
       "   NoteCC_26_i1  target  id_genre  datenaiseleve  nationalite  id_handicap  \\\n",
       "0        14.335     0.0         1           2002            1          0.0   \n",
       "\n",
       "                                   Adress  Préscolarisé profession_mere  \\\n",
       "0    حي الانارة زنقة1 درب16 رقم 173 مكناس             1         inconnu   \n",
       "\n",
       "  profession_pere  Level  \n",
       "0         Général      8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286548, 58)\n",
      "114507\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[data['target']==1].shape[0]+data[data['target']==2].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def get_split(dff):\n",
    "    y = dff['target']\n",
    "    X = dff.drop('target', axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    return  X_train, X_test, y_train, y_test\n",
    "\n",
    "def Split_Random(df):\n",
    "\n",
    "    df1= df[df[\"id_annee\"]==9]\n",
    "    X_train1, X_test1, y_train1, y_test1 = get_split(df1)\n",
    "    df2=df[df[\"id_annee\"]==10]\n",
    "    X_train2, X_test2, y_train2, y_test2 = get_split(df2)\n",
    "    df3=df[df[\"id_annee\"]==11]\n",
    "    X_train3, X_test3, y_train3, y_test3 = get_split(df3)\n",
    "    df4=df[df[\"id_annee\"]==12]\n",
    "    X_train4, X_test4, y_train4, y_test4 = get_split(df4)\n",
    "    \n",
    "    X_train=pd.concat([X_train1, X_train2, X_train3, X_train4], axis=0)\n",
    "    X_test=pd.concat([X_test1, X_test2, X_test3, X_test4], axis=0)\n",
    "    y_train=pd.concat([y_train1, y_train2, y_train3, y_train4], axis=0)\n",
    "    y_test=pd.concat([y_test1, y_test2, y_test3, y_test4], axis=0)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "    X_train=X_train.drop(['id_annee','cd_etab'], axis=1)\n",
    "    X_val=X_val.drop(['id_annee','cd_etab'], axis=1)\n",
    "    X_test=X_test.drop(['id_annee','cd_etab'], axis=1)\n",
    "    X_train=pd.concat([X_train, X_val], axis=0)\n",
    "    y_train=pd.concat([y_train, y_val], axis=0)\n",
    "    return  X_train, X_test, y_train, y_test   \n",
    "     \n",
    "def custom_normalize(x):\n",
    "    return ((x - x.min()) / (x.max()-x.min()))\n",
    "\n",
    "def normalize_group(group):\n",
    "    scaler = MinMaxScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(group), columns=group.columns, index=group.index)\n",
    "\n",
    "def Feature_engineering(df):\n",
    "    df['School_period'] = (df['id_annee'] +2007)-df['DO_ETAB_i1']\n",
    "    df=df.drop(['DO_ETAB_i1'], axis=1)\n",
    "    \n",
    "    df['age'] = ( df['id_annee'] +2007)-data['datenaiseleve'] \n",
    "    df = df.drop(['datenaiseleve'], axis=1)\n",
    "    \n",
    "    # Text features\n",
    "    categorical_columns = ['profession_pere','profession_mere']\n",
    "    encoder = LabelEncoder()\n",
    "    for column in categorical_columns:\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "        \n",
    "    # Normalisation\n",
    "    scaler = MinMaxScaler()\n",
    "    # General Normalization\n",
    "    columns_to_normalize=[ 'profession_pere','profession_mere','NbrJourAbsenceAutorise_i1','NbrUniteAbsenceAutorise_i1', 'NbrJourAbsenceNonAutorise_i1','NbrUniteAbsenceNonAutorise_i1',\n",
    "                          'failure_i1', 'MoyenneClasse_i1','age','School_period', 'Nb_class_failure_i1','Nb_class_dropout_i1','nbr_eleves_i1', 'nbr_filles_i1','Multiclass_i1','Level_i1','Classment_class_i1',\n",
    "                         'Coefficients_CC_11_i1', 'Coefficients_CC_12_i1', 'Coefficients_CC_18_i1', 'Coefficients_CC_19_i1', 'Coefficients_CC_20_i1', 'Coefficients_CC_23_i1', 'Coefficients_CC_24_i1', \n",
    "                          'Coefficients_CC_26_i1'] \n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "    # Normalization by class\n",
    "    columns_to_normalize_class = ['MoyenneGen_i1','NoteCC_11_i1','NoteCC_12_i1', 'NoteCC_18_i1', 'NoteCC_19_i1', 'NoteCC_20_i1','NoteCC_23_i1', 'NoteCC_24_i1', 'NoteCC_26_i1']\n",
    "    # Group by 'class_id' and apply Min-Max normalization within each group\n",
    "    df[columns_to_normalize_class] = scaler.fit_transform(df[columns_to_normalize_class])\n",
    "\n",
    "    # Feature encoding\n",
    "    columns_to_encode = ['target_i1','cd_prov_i1','id_handicap']\n",
    "    df[\"id_genre\"] = df[\"id_genre\"] - 1\n",
    "    # Get dummy variables for the specified columns\n",
    "    df = pd.get_dummies(df, columns=columns_to_encode)\n",
    "\n",
    "    # New features     \n",
    "    df['Average_scientific_subjects_i1'] = df[['NoteCC_19_i1', 'NoteCC_20_i1', 'NoteCC_23_i1']].mean(axis=1)\n",
    "    df['Average_literary_subjects_i1'] = df[['NoteCC_11_i1', 'NoteCC_12_i1', 'NoteCC_18_i1', 'NoteCC_24_i1']].mean(axis=1)\n",
    "\n",
    "    # Drop columns        \n",
    "    df=df.drop(['Level_i1','Adress','AdresseL_i1','Level','id_classe','CD_REG_i1','White_year_i1','CD_REG_i1','id_eleve'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At-risk or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.683780727836174\n",
      "Test 0.12067437218197301\n"
     ]
    }
   ],
   "source": [
    "data2 = Feature_engineering(data)\n",
    "data2.loc[data2[\"target\"] == 2, \"target\"] = 1\n",
    "X_train, X_test, y_train, y_test    =Split_Random(data2)\n",
    "print(\"Train\",X_train.shape[0]/data2.shape[0])\n",
    "print(\"Test\",X_test.shape[0]/data2.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 74932, number of negative: 121004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4464\n",
      "[LightGBM] [Info] Number of data points in the train set: 195936, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382431 -> initscore=-0.479243\n",
      "[LightGBM] [Info] Start training from score -0.479243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Accuracy: 0.802\n",
      "Precision: 0.791\n",
      "Recall: 0.789\n",
      "F1-score: 0.790\n",
      "AUC: 0.789\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=500,  # Number of boosting iterations\n",
    "    boosting_type='gbdt',  # Boosting type\n",
    "    objective='binary',  # Objective function\n",
    "    max_depth=6,  # Maximum tree depth\n",
    "    random_state=12,  # Random state for reproducibility\n",
    "    \n",
    ")\n",
    "\n",
    "# Train the LightGBM classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'F1-score: {f1:.3f}')\n",
    "print(f'AUC: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 74932, number of negative: 121004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4464\n",
      "[LightGBM] [Info] Number of data points in the train set: 195936, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382431 -> initscore=-0.479243\n",
      "[LightGBM] [Info] Start training from score -0.479243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Accuracy: 0.803\n",
      "Precision: 0.792\n",
      "Recall: 0.790\n",
      "F1-score: 0.791\n",
      "AUC: 0.790\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import mlflow\n",
    "\n",
    "# Set the tracking URI\n",
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000/')\n",
    "mlflow.set_tracking_uri('/home/elmehdi.arejdal/Code_ismail/__Deployment__/workspace/experiments/mlruns')\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment('experiment_1')\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'n_estimators': 900,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'max_depth': 6,\n",
    "        'random_state': 12\n",
    "    }\n",
    "\n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Define the LightGBM classifier\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "    # Train the LightGBM classifier\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1-score\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    print(f'Precision: {precision:.3f}')\n",
    "    print(f'Recall: {recall:.3f}')\n",
    "    print(f'F1-score: {f1:.3f}')\n",
    "    print(f'AUC: {auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
